# Classification_metrics

**Dataset** can be download from https://www.kaggle.com/uciml/pima-indians-diabetes-database

## Highlight some basic points with code like:
* Classification accuracy: percentage of correct predictions
* Null accuracy
* Comparing the true and predicted response values
* **Confusion matrix**
* **Metrics computed from a confusion matrix**
  * **Classification Accuracy:** Overall, how often is the classifier correct
  * **Classification Error:** Overall, how often is the classifier incorrect?
  * **Sensitivity:** When the actual value is positive, how often is the prediction correct?
  * **Specificity:** When the actual value is negative, how often is the prediction correct?
  * **False Positive Rate:** When the actual value is negative, how often is the prediction incorrect?
  * **Precision:** When a positive value is predicted, how often is the prediction correct?
* **Adjusting the classification threshold**
* **ROC Curves and Area Under the Curve (AUC)**
  * AUC is the percentage of the ROC plot that is underneath the curve:
